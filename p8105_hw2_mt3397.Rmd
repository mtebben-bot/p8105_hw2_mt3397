---
title: "HW 2"
output: github_document
---

```{r libraries}
library(tidyverse)
library(readxl)
```

## Problem 1

Read in the Mr. Trash Wheel dataset.

```{r trashwheel_read}
trashwheel_df = 
  read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
             range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
    )
```

Read in precipitation data.

```{r precipitation2018_read}
precip2018 = 
  read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
             sheet = "2018 Precipitation",
             skip = 1
             ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year) 
```

```{r precipitation2017_read}
precip2017 = 
  read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
             sheet = "2017 Precipitation",
             skip = 1
             ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Combine 2017 and 2018 precipitation data frames.

```{r bind_20172018_precip}
precip_df = 
  bind_rows(precip2017, precip2018) %>% 
  mutate(month = month.name[month])
```

This data set contains information from a Mr. Trash Wheel trash collector from Baltimore, Maryland. As trash enters the harbor, the trash wheel collects trash and stores it in a dumpster. The data set contains information on year, month, and trash collected, including some specific kinds of trash. Additional data sheets include precipitation data by month and year. There are a total of `r nrow(trashwheel_df)` rows in our cleaned Mr. Trash Wheel data set.
The precipitation data frame we created contains monthly precipitation totals for the years 2017 and 2018.

```{r 2018_precip_total}
precip_2018_total = 
  read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
             sheet = "2018 Precipitation",
             skip = 1
             ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  mutate(month = month.name[month]) %>% 
  relocate(year) %>% 
  summarise_if(is.numeric, sum)
```

The total precipitation in 2018 is 70.3 inches.

```{r 2017_median_sports_balls}
balls2017_df = 
  read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
             range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  select(year, sports_balls, dumpster) %>% 
  drop_na(dumpster) %>% 
  filter(year == 2017) %>% 
  summarise_if(is.numeric, median)
```

The median number of sports balls in a dumpster in 2017 is 8.

## Problem 2

First, read in the csv file and clean data.

```{r read_and_clean_subway}
subway = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_longitude, station_latitude, entrance_type, entry, vending, ada,
         starts_with("route")) %>% 
  mutate(entry = recode(entry, YES = TRUE, NO = FALSE))
```

This dataset contains information about the NYC subway, including the line, station name and location (longitude and latitude), entrance type and whether or not entry is allowed, as well as ADA compliance, routes at each station, and whether or not vending is present. I cleaned the names and selected the variables of interest. Additionally, I recoded entry as a logical variable. There are 19 variables and 1858 rows in this data frame. This is not tidy data.

```{r answering_questions}
distinct_nyc = 
  subway %>% 
  distinct(line, station_name)

ada_nyc = 
  subway %>% 
  filter(ada == TRUE)

entry_nyc = 
  subway %>% 
  select(entry, vending) %>% 
  filter(vending == "NO") %>% 
  summary()
```

There are `r nrow(distinct_nyc)` distinct stations. `r nrow(ada_nyc)` stations are ADA compliant. There are 183 stations without vending, and 69 of them allow entry, so 37.7% of stations without vending have entry.

#### Next, we need to make route name and route number distinct variables.

```{r route_name_number}
tidysubway =
  subway %>% 
  mutate_at(vars(route1:route11), as.character) %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    names_prefix = "route",
    values_to = "route_name"
  ) %>% 
  drop_na(c("route_name","route_number")) 
```

Then, we can answer the questions about distinct A stations and ADA compliant A stations.

```{r A_distinct_ADA}
distinct_A = 
tidysubway %>% 
  filter(route_name == "A") %>% 
  distinct(station_name, line)

ADA_A = 
  tidysubway %>% 
  filter(
    route_name == "A",
    ada == TRUE
    ) %>% 
  distinct(station_name, line)
```

There are `r nrow(distinct_A)` distinct stations that serve the A train. There are `r nrow(ADA_A)` ADA compliant stations that serve the A train.

## Problem 3

First, we need to clean the pols_month.csv data.

```{r pols_month}
pols_df = 
  read_csv("./data/pols-month_hw2.csv") %>% 
  separate(mon, into = c("year", "month", "day"), convert = TRUE) %>% 
  mutate(
    month = month.name[month],
    president = if_else(prez_gop == 1, "gop", "dem")) %>% 
  arrange(year) %>% 
  select(-day, -prez_dem, -prez_gop)
```

Then, we need to clean snp.csv data.

```{r snp}
snp_df = 
  read_csv("./data/snp_hw2.csv") %>% 
  separate(date, into = c("month", "day", "year"), convert = TRUE) %>% 
  mutate(month = month.name[month]) %>% 
  select(-day) %>% 
  relocate(year) %>% 
  arrange(year, match(month, month.name))
```

Finally, we need to clean unemployment.csv data.

```{r unemployment}
unemploy_df = 
  read_csv("./data/unemployment_hw2.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "pct_unemployment"
  ) %>% 
  mutate(month = recode(month, "jan" = "January", "feb" = "February", "mar" = "March", "apr" = "April", "may" = "May", "jun"= "June", "jul" = "July", "aug" = "August", "sep" = "September", "oct" = "October", "nov" = "November", "dec" = "December"))
```

#### Now, we can merge datasets.

```{r join}
pols_snp_df = 
  full_join(pols_df, snp_df, by = c("year", "month"))

five38_df = 
  full_join(pols_snp_df, unemploy_df, by = c("year", "month"))
```

The pols data set, which has `r nrow(pols_df)` observations, includes monthly data on the number of politicians in Congress by party and the party of the sitting president from January 1947 through June 2015. The snp data set, which has `r nrow(snp_df)` observations, gives the monthly closing values of the S&P 500 starting in January 1950 and going through July 2015. The unemployment data set, which has `r nrow(unemploy_df)` observations, includes monthly unemployment percentages starting in January 1948 and going through December 2015.

The resulting data set has `r nrow(five38_df)` observations, including monthly data on the parties of politicians in Congress and the White House, as well as unemployment percentages and S&P 500 closing values from January 1947 through December 2015. It makes sense that this merged data set would have more observations, as I carried out a full join, which means that any month and year that exists in any of the three data sets will be present, even if there are NA values for some of the data.

